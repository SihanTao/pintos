            +----------------------+
            |        OS 211        |
            |  TASK 1: SCHEDULING  |
            |    DESIGN DOCUMENT   |
            +----------------------+
                   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Tao Sihan <st2220@ic.ac.uk>
Liu Tony  <tl2020@ic.ac.uk>
Lin Yijun <yl6220@ic.ac.uk>
Foo Jonathan <jjf120@ic.ac.uk>

---- PRELIMINARIES ----

>> If you have any prelziminary comments on your submission, or notes for the
>> markers, please give them here.

>> Please cite any offline or online sources you consulted while preparing your 
>> submission, other than the Pintos documentation, course text, lecture notes 
>> and course staff.

None

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> A1: (2 marks) 
>> Copy here the declaration of each new or changed `struct' or `struct' member,
>> global or static variable, `typedef', or enumeration.  
>> Identify the purpose of each in roughly 25 words.

Added to struct thread:

    /* used to store the locks that the thread holds, member for implementing
    thread_get_effective_priority and lock_acquire. */
    struct list list_of_locks;

    /* to store the value of recent_cpu for calculating priority. */
    fixed_point_t recent_cpu;          


Added to struct lock:

    /* used in struct thread member list_of_locks to store locks acquired. */
    struct list_elem elem;      

Added to struct semaphore_elem:

    /* used store the thread which wait for the conditional. */
    struct thread *holder;

Created a new file fixed-point.h to store the fixed-point arithmetic operations: 
    
    /* define a int32_t for the later implementation of struct thread and recent_cpu */
    typedef int32_t fixed_point_t;

Added to thread.c as global varible: 

    /* used in thread_tick_mlfqs to check the load_avg for every 100 ticks*/
    static inline void update_load_avg (void);


>> A2: (4 marks) 
>> Draw a diagram that illustrates a nested donation in your structure and 
>> briefly explain how this works.

Assume each thread holds a number of locks with empty waiters initially.
Suppose that thread A with priority Low acquired lock1 and other locks. Since there's no waiters on each 
lock of A, thread A's effective priority will be it's own priority - Low;

Now, suppose that thread B with priority Medium holds lock2 and other locks, attempts 
to acquire lock1. It will be put into lock1's semaphore waiter list. Then, thread_get_effective_priority(A) 
will return the maximum of its own priority and the "lock priority" of all locks of A;

thread_get_effective_priority(A) = max (A->priority, lock_priority(lock1), lock_priority(locks held by A)...)

and the lock_priority is given by the maximum of effective priority of threads in its waiter list

lock_priority(lock1) = max (thread_get_effective_priority(B), thread_get_effective_priority(all thread waiting for lock1)) 
 
But B is the only thread waiting for lock1, so lock_priority(lock1) = thread_get_effective_priority(B)

Since B holds zero lock, thus lock_acquire(lock1) = effective of thread B = B's base priority = Medium.

Thus, thread A will have effective priority Medium now. 

Suppose that thread C with priority High attempt to acquire lock2. it will be put into lock2's semaphore 
waiter list. 

again

thread_get_effective_priority(A) = max (A->priority, lock_priority(lock1), lock_priority(lock2), lock_priority(other locks held by A)...)

thread_get_effective_priority(A) gives the lock_priority(lock2) since 

```
lock_priority(lock2) = max (thread_get_effective_priority(C), thread_get_effective_priority(all thread waiting for lock2)) 
```
lock_priority(lock2) is the highest among A and other priority of locks that A holds

Now there are two situations, release lock1 first or release lock2 first.

Consider the first situation, relase lock 1 and then release lock2.

After release lock 1, the effective priority of thread A is given by

```
thread_get_effective_priority(A) = max (A->priority, lock_priority(lock2), lock_priority(other locks held by A)...)
```

since lock1 is released.

But the effective priority of A is unchanged (High), because lock_priority(lock2) is the maximum (High).

Then release lock2.

After release lock 1, the effective priority of thread A is given by

```
thread_get_effective_priority(A) = max (A->priority, lock_priority(other locks held by A)...)
```
Because lock2 is released, the effective priority falls back to Low.

Consider situation 2, first lock2 is released.

 the effective priority of thread A is given by

```
thread_get_effective_priority(A) = max (A->priority, lock_priority(lock1), lock_priority(other locks held by A)...)
```

The effective priority of thread A is given by lock_priority(lock1), which is Medium;

then lock1 is released, thus the effective priority of A is its base priority;


---- ALGORITHMS ----

>> A3: (3 marks) 
>> How do you ensure that the highest priority waiting thread wakes up first for
>> a (i) lock, (ii) semaphore, or (iii) condition variable?

    (i) Sturture of lock contains a semaphore. 

        when release a lock, `sema_up` is called. Which is described below. 

    (ii) The sturture of semaphore contains a list of waiters. 

        `sema_up` would call `thread_unblock` put the thread
        into one of the 64 ready queues according to its effective priority; And if its effective priority is higher than
        the current running thread, in thread_unblock it will yield the current thread to let the new thread run. 
        In thread_yield, we insert the current thread into the ready_list in an increasing order of effective 
        priority, unless it is idle thread. Then call scheduler to switch the thread. 

    (iii)

        We changed the functions cond_wait and cond_signal. 
        In cond_wait, we store the thread waiting for conditional variable to be the current thread.
        In cond_signal, every time we wake up the thread with the highest priority waiting for the condition using list_max.



 
    
    thread_get_effective_priority(t) will call get_lock_priority() on 
    thread t's list_of_locks and return the highest lock_priority or t's priority,
    whichever higher. get_lock_priority(l) will call thread_get_effective_priority() 
    on l's waiters and return the highest thread_priority or return 0 if there's no waiter. 
    The current running thread must have the highest priority of all threads in ready list, 
    only when a new thread with higher priority is created or a thread with higher priority 
    is unblocked or the current running thread release the lock that a higher priority thread is waiting for, 
    then we call thread_yield()

>> A4: (3 marks)
>> Describe the sequence of events when a call to lock_acquire() causes a 
>> priority donation. 
>> How is nested donation handled?

    Suppose we have thread A with base priority Low and thread B with base priority Medium and thread 
    C with base priority High. Suppose now A holds Lock1 and thread B calls lock_acquire(Lock1), B holds Lock2 
    and C calls lock_acquire(Lock2).

    B calls lock_acquire, which then calls sema_down. This first push thread B back into the waiter list of the 
    semaphore and then call thread_block to block thread B.  

    get_lock_priority() first finds the max_priority_thread in its semaphore.waiters,
    and get the effective priority of the max_priority_thread.
    Here thread B is in the waiters and it is the max_priority_thread. Since B is trying to acquire lock1, the effective priority is equal to its base priority.
    Hence the 'lock priority' is Medium now. And through all the function calls, thread A has Medium priority 

    In thread_block, we call schedule() , where the next thread to run is determined by the function
    next_thread_to_run. This function use list_max to find the max priority thread to run.
    list_max use list_less_func (here is less_thread_effective_priority).

    less_thread_effective_priority compare the effective priority of two threads by 
    the function thread_get_effective_priority().

    If the thread does not acquire any lock then return its own priority 
    else obtain the lock with the highest lock_priority to compare with 
    thread priority and return the larger one.

    A calls lock_acquire, which then calls sema_down. This first push thread A back into the waiter list of the 
    semaphore and then call thread_block to block thread A.  

    Now thread B has High priority. After it release Lock2, its effective priority falls back to Medium.

    As well if we call thread_get_effective_priority(thread A).

    Because lock2 is released, the effective priority falls back to Low.

    The effective priority of A is now Medium so it will run and release lock1 then its priority will fall back to Low. 

>> A5: (3 marks)
>> Describe the sequence of events when lock_release() is called on a lock that 
>> a higher-priority thread is waiting for.

    Suppose we have thread A with base priority Low and thread B with base priority High. Suppose now A holds Lock1 and thread B calls lock_acquire(Lock1). 

    B calls lock_acquire, which then calls sema_down. This first push thread B back into the waiter list of the 
    semaphore and then call thread_block to block thread B.  

    get_lock_priority() first finds the max_priority_thread in its semaphore.waiters,
    and get the effective priority of the max_priority_thread.
    Here thread B is in the waiters and it is the max_priority_thread. Since B is not holding any locks, 
    (it is trying to acquire lock1), the effective priority is equal to its base priority.
    Hence the 'lock priority' is High now. And through all the function calls, thread A has High priority. 

    In thread_block, we call schedule() , where the next thread to run is determined by the function
    next_thread_to_run. This function use list_max to find the max priority thread to run.
    list_max use list_less_func (here is less_thread_effective_priority).

    less_thread_effective_priority compare the effective priority of two threads by 
    the function thread_get_effective_priority().

    If the thread does not acquire any lock then return its own priority 
    else obtain the lock with the highest lock_priority to compare with 
    thread priority and return the larger one.

    As well if we call thread_get_effective_priority(thread A).

    Because A has high priority now, it will run and release Lock1. 

    When lock_release is called, remove the lock from the list of threads that tries to acquire the lock and
    reset the holder of the lock to null. The it calls sema_up to the semaphore of the current lock. 

    Because Lock1 is released, the effective priority of thread A falls back to Low.

   

---- SYNCHRONIZATION ----

>> A6: (2 marks)
>> How do you avoid a race condition in thread_set_priority() when a thread 
>> needs to recompute its effective priority, but the donated priorities 
>> potentially change during the computation?
>> Can you use a lock to avoid the race?

    When thread_set_priority is called it store the priority of the current thread in an int called 
    old_priority. Also, it compares the old_priority to new_priority to check if the current thread 
    still has the highest priority. If not then thread_yield is called for the scheduler to reschedule
    all the threads. 

    Our implementation avoid race condition when calling thread_yield(). Every time thread_yield is called, we first disable 
    all the interrupts and then use a less function to reorder the priority of all threads in the ready list. This prevents 
    a race condition to happen. 

    No. If we use a lock in thread_set_priority to avoid race condition. Then when a main thread tries to change its own priority, 
    it will be bloked and cause deadlock. 

---- RATIONALE ----

>> A7: (3 marks)
>> Why did you choose this design?  
>> In what ways is it superior to another design you considered?



              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> B1: (2 marks)
>> Copy here the declaration of each new or changed `struct' or `struct' member,
>> global or static variable, `typedef', or enumeration. 
>> Identify the purpose of each in roughly 25 words.

Added to struct thread:

    /* used to store the locks that the thread holds, member for implementing
    thread_get_effective_priority and lock_acquire. */
    struct list list_of_locks;

    /* to store the value of recent_cpu for calculating priority. */
    fixed_point_t recent_cpu;          


Added to struct lock:

    /* used in struct thread member list_of_locks to store locks acquired. */
    struct list_elem elem;      

Added to struct semaphore_elem:

    /* used store the thread which wait for the conditional. */
    struct thread *holder;

Created a new file fixed-point.h to store the fixed-point arithmetic operations: 
    
    /* define a int32_t for the later implementation of struct thread and recent_cpu */
    typedef int32_t fixed_point_t;

Added to thread.c as global varible: 

    /* used in thread_tick_mlfqs to check the load_avg for every 100 ticks*/
    static inline void update_load_avg (void);


---- ALGORITHMS ----

>> B2: (3 marks)
>> Suppose threads A, B, and C have nice values 0, 1, and 2 and each has a 
>> recent_cpu value of 0. 
>> Fill in the table below showing the scheduling decision, the priority and the
>> recent_cpu values for each thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0     0   0   0   63  61  59   A   
 4     4   0   0   62  61  59   A
 8     8   0   0   61  61  59   B
12     8   4   0   61  60  59   A 
16     12  4   0   60  60  59   B
20     12  8   0   60  59  59   A
24     16  8   0   59  59  59   C
28     16  8   4   59  59  58   B 
32     16 12   4   59  58  58   A 
36     20 12   4   58  58  58   C 

>> B3: (2 marks) 
>> Did any ambiguities in the scheduler specification make values in the table 
>> uncertain? 
>> If so, what rule did you use to resolve them?
FIFO

---- RATIONALE ----

>> B4: (3 marks)
>> Briefly critique your design, pointing out advantages and disadvantages in 
>> your design choices.
Very good